<h1 align="center">ğŸ•·ï¸ WebScrapeX</h1>
<p align="center">
  <em>A visually stunning MERN-based web scraper that extracts HTML, links, and images from any website in seconds.</em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/MERN%20Stack-Ready-green?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Scraper-Built%20with%20Cheerio-blueviolet?style=for-the-badge" />
</p>

---

## ğŸŒ What is WebScrapeX?

**WebScrapeX** is a **modern web scraping platform** built on the MERN stack that allows users to enter a URL and instantly extract:

- ğŸ”— All hyperlinks (`<a href="...">`)
- ğŸ–¼ï¸ All images (`<img src="...">`)
- ğŸ§± Raw HTML (`<html>...</html>`)

All via a beautifully designed, responsive UI.

Perfect for:
- Quick data extraction
- SEO & content audits
- Dev research
- Competitive analysis

---

## âœ¨ Features

- ğŸ§  **Enter any URL** â€” and let WebScrapeX fetch its content
- ğŸ” **Preview Extracted Data** â€” view all links, images, and HTML cleanly
- ğŸ–¼ï¸ **Grid-style Image Gallery** â€” all fetched images shown instantly
- ğŸ§¾ **Expandable HTML Viewer** â€” prettified raw HTML output
- ğŸ’… **Sexy, responsive UI** â€” built with Tailwind CSS and React
- ğŸ” **Optional user login** â€” for saving scraping history (beta)

---

## ğŸ› ï¸ Tech Stack

| Layer       | Technology            |
|------------|------------------------|
| ğŸ–¥ Frontend | React.js, Tailwind CSS |
| ğŸ§  Backend  | Node.js, Express.js    |
| ğŸ›¢ DB       | MongoDB + Mongoose     |
| ğŸ•¸ï¸ Scraper  | Cheerio, Axios         |
| ğŸ” Auth     | JWT + bcrypt (optional) |

---

## âš™ï¸ Setup Instructions

### ğŸ”§ Prerequisites

- Node.js (v14+)
- MongoDB installed or Atlas instance

### ğŸ“¦ Installation

```bash
# Clone the repo
git clone https://github.com/yourusername/webscrapex.git
cd webscrapex
````

```bash
# Backend setup
cd backend
npm install

# Frontend setup
cd ../frontend
npm install
```

### ğŸ”‘ Environment Variables (`/backend/.env`)

```env
PORT=5000
MONGO_URI=your_mongodb_uri
JWT_SECRET=your_secret_key (if using auth)
```

### ğŸš€ Run the App

```bash
# In backend folder
npm run dev

# In frontend folder
npm start
```

---

## ğŸ§© How It Works

1. User enters a URL into the frontend form
2. Backend uses `axios` to fetch the HTML and `cheerio` to parse it
3. Extracts:

   * All `<a>` tags (links)
   * All `<img>` tags (images)
   * The raw HTML body
4. Results are returned to the frontend
5. UI displays:

   * Gallery view for images
   * Collapsible HTML code block
   * Clickable external links

---

## ğŸ–¼ UI Preview

<p align="center">
  <img src="https://your-image-link.com/scraper-ui.png" width="800" alt="WebScrapeX UI preview" />
</p>

---

## ğŸ“‚ Folder Structure

```
webscrapex/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ utils/scraper.js
â”‚   â””â”€â”€ server.js
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ App.js
```

---

## ğŸ”¥ Feature Roadmap

* ğŸ“ Download results as JSON or CSV
* ğŸ’¾ Save past scrapes to user dashboard
* ğŸ§  AI-enhanced scraping (summarization, keyword analysis)
* ğŸ¯ Domain-specific scraping (e.g., blogs, ecommerce)
* ğŸ§© Chrome extension for 1-click scraping

---

## ğŸ¤ Contributing

We â¤ï¸ contributions!

1. Fork it
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some feature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“œ License

Distributed under the MIT License. See `LICENSE` for more info.
